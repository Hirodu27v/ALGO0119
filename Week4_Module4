このMOOCの最後の専門家インタビューです。
今日はドイツのDer Spiegelの編集委員であるクリスティーナ・エルマーさんにご登場いただきます。デア・シュピーゲルDer Spiegelはここ1年ほど、アルゴリズムと社会について実に興味深い調査を行ってきました。このようなプロジェクトについてもっと知りたいと思っています。
クリスティーナさん、ようこそ。これらの調査についてＭＯＯＣに参加する私たちとこうして共有していただけることに感謝します。

こちらこそ。

まずＭＯＯＣの学生にあなたを紹介したいと思います。とても国際色豊かなのでシュピーゲルをよく知らない人がいるかもしれません。
まずはシュピーゲルと、そこでのあなたの役割について少し話してもらえないでしょうか。

はい シュピーゲルはドイツのニュース週刊誌で、1947年に創刊され、1994年からは自前のニュースサイト「シュピーゲル・オンライン」も運営しています。
このニュースサイトは独立した編集チームとデータに基づいた編集局を擁し、読者は毎月約2100万人を数えます。これがユニークユーザー数です。そして、そのほとんどがドイツ国内にいます。
私はシュピーゲルオンラインで科学編集者としてスタートし、４人の異なる技能を持つ同僚とともにデータジャーナリズム部門を立ち上げました。
うち２人はコーディングを学ぶジャーナリスト、残り２人は元々都市計画の専門家で自分のブログで作品を発表していました。
チームのバックグラウンドはとても多様で、それ自体がすでに様々な視点を兼ね備えているのです。
私は昨年までこのチームを率いていましたが、今はシュピーゲル・オンライン編集委員会のメンバーです。

今週のMOOCのトピックの一つは、社会で稼働しているアルゴリズムの調査についてです。シュピーゲルがいくつかの調査をしたことは知っています。
あなたは最近、データジャーナリズムハンドブックの章を担当しましたね。あなたが行ってきた調査について、もう少し詳しく教えていただけないでしょうか。

私たちは、アルゴリズムが既に社会の多くの重要な分野に影響を与えていると考えています。ですから、この方向に進むのは自然なことでした。
ここ数年、シュピーゲル・オンラインでは、アルゴリズムの説明責任について議論してきました。しかし当初は、単発の報道の機会としてであって、アルゴリズムを包括的に分析する調査やプロジェクトの形を取りませんでした。
先述の通り、データジャーナリズムのチームは小規模で、大きなデータ分析ユニットなどはありません。そのため、2017年にはドイツの連邦選挙に向けて、Ableism WatchというＮＰＯと協力し、このようなプロジェクトを開始しました。
彼らはこの分野では先駆的な専門家で、Googleの検索結果の表示をめぐる洞察を得るために協力してくれました。私たちは彼らと一緒にクラウドソーシングを行いました。彼らは分析を行い、その結果を共同発表しました。
このプロジェクトでは、私たちデータジャーナリズム部門が企画・方法論・運用評価までをサポートしました。全てを自分たちで行うのではなく、多かれ少なかれ協働できたのは、このトピックにおいてはいい考えでした。
その結果、（連邦選挙では）パーソナライゼーションはあまり強くなかったことが分かりました。この調査によって、広まっている俗説を覆すことはできましたが、期待した結果は得られませんでした。

これはいわゆるフィルターバブルとGoogleの検索結果といった話ですよね。

そうですね、私たちの疑問は、フィルターバブルは本当に存在するのか、特にそれはIPアドレスのようなローカルな位置情報に基づいて異なる検索結果が出るということなのかということでした。
人々はこれまで、フィルターバブルが実在していて、居場所によって異なるフィルターバブルを識別することができるのかどうか考えてきました。
しかし、Googleのニュース検索結果で最初に表示されるものは、地域によってさほど違いがないことが分かりました。少なくとも、あなたが今どこにいるかによって検索結果に違いはないのです。
そして同時に、これまでプロパブリカがアメリカの（選挙）広告を収集していて、これをヨーロッパのいくつかの国でもやってみようと考えていたので、ちょうどドイツは最適な国でした
ここでの目標は、Facebookのターゲティング広告がドイツの政党によって行われているかどうかを明らかにすることでした。
政党はもちろんこのオプションを使用して、例えばメッセージで特定のターゲットグループに直接接触しようとすると考えました。
しかし再び、これらの政党はあまりターゲティング広告は使っていないことが判明しました。
もちろん、すべての広告を収集すること、特にローカル広告の概要を把握するのは非常に有意義なことでした。政党が行ったのはローカル広告だったのです。
合理的にも、彼らは地元の政治グループの広告だけを公開しました。ハンブルグからこうした広告は見ることができません。
この有用なプロジェクトによって、透明性を高めることができました。読者はそれらを収集した、カタログのようなこのサイトにアクセスすることができます。
またしても、期待した結果とはなりませんでした。昨年、アルゴリズムの説明責任をめぐる報道は大変面白い展開を見せました。
私たちは（大手個人信用情報機関）シューファーが個人の信用力を評価するための信用報告書と記録に用いられている強力なアルゴリズムを調査しました。
ドイツでは銀行口座や携帯電話の申し込みをする際に非常に（シューファーが評価する信用力が）重要です。他にも、アパートの入居とか。
あなたが家賃を払えることを証明するには、シューファーのレポートを用意する必要があります。このアルゴリズムはドイツでは非常に重要ですが、全く透明性がありません。
再びクラウドソーシングをすることを決め、以前からよく知っているミュンヘンにあるバイエルン放送のデータチームと協力することにしました。
私たちは異なるターゲットグループをもっています。彼らは放送、私たちは雑誌とオンラインという異なる分野で報道に携わっていますが、多かれ少なかれ共通する部分もあります。
これらのストーリーを共同で発表することで、互いに損をしないようにしました。そしてこれはとてもうまくいきました。
また、ドイツの二つのNGOにも協力してもらいましたが、これは元々彼らのアイデア、彼らのテーマだったのです。
そこでクラウドソーシングは、二つの（NGOの）データチームと、メディアのデータチームが、データセットに基づいて調査することになりました。

それらのデータセットから、シューファーの信用スコアについて何を見つけましたか？

2012年頃（のデータセット）だと思いますが、2500種類のレポートがクラウドソーシングされたので、あらゆる面でどのように機能しているのかを詳細に調べることはできませんでした。
膨大な数ではありましたが、ある項目について調べ上げることができないほどではありませんでした。
信用スコアのソースからは、高齢者や女性が、住所変更の頻度が低い人と同じように有利だと言えるのはとても興味深い結果でした。
信用スコアは異なるバージョンのシステムで評価されていることも分かりました。つまり、同じ経歴の人物でも異なる結果が出るということです。

So depending on which bank you you are having your money on, you can get different results.
So some banks used older versions while others have already updated their systems and that
has not been made transparent at all and reports and discriminated against certain groups of
people. So there have been some some yeah. Some results.
So you know it seems like across all these products you mentioned a lot about collaboration and
working with other teams. I wonder if you could sort of elaborate on that and sort of explain
more about how you organize these types of projects both within your own team and your own
organization and also working with these with these other organizations and groups like what
kind of skills do you need on these teams in order to pull off these really big projects.
I think you definitely need your own data journalism department besides all those collaboration
possibilities because you need the colleagues who can handle huge sets of documents and
huge data sets in-house but they should also be able to write the necessary code and assess
the journalistic relevance of the results because this is a back and forth that we always have in
such projects that we see something in the data sets and we have to ask ourselves Is this really
worth it? And worth it and is this really a result that we would publish and yet concerning or
relating to our journalistic relevance criteria. So we have to have both on board and I think you
often need to have a methodology for understanding the team how such a crowd sourcing
process can work because you have to set up this like design framework for us with all your
partners. I think many other things can be done via collaborations with other data sets or NGOs
or scientific partners for example.
But I think it's crucial to have your own team working on the data set with a journalistic view.
And we saw that. I mean we brought together different factors from different systems so we first
had to discuss our relevance criteria. We had to discuss the requirements and the capabilities
beforehand. Also how would you report on the results. What would you say? What what is the
one sentence that we all should be using not in terms of PR but in terms not to get anything
wrong. And we of course had working towards that we use together for example with the Varian
data team. We had Slack channel that was on our workspace and select only set up for this
project because it's so big that you really need some. Yeah I won't call Slack elaborate but you
need to be to make more yet. You need such tools yeah.
And then what about sort of the external collaborators. How did you think about what they were
bringing to the table in terms of these projects?
I think they could approach the topic from a different angle. That was quite helpful. For example
the NGOs could really fight for the crowdsourcing and really come up with with their really
distinguished opinion about making this transparent and also be a bit more aggressive on that. I
would say. [Video skips] it was more like we we what we are not neutral because we think
transparency is really important but concerning the algorithm itself. We want to be be more
neutral compared to the NGOs and we should also be independent from them. So because in
the end we publish results and we want to be taken seriously by the public but also by the
Schufar for example which is a company making a lot of money out of this algorithm. So we had
to stay independent. So this is what NGOs can bring in and concerning the scientific partners.
Some of them have also been involved in the Algorithm Watch Project in the run up to the
elections. They can really bring in methodology and capabilities in terms of analysis skills and
Data Handling and the like like they could program the the Firefox add on that we use for
example to collect all those or those search results whereas ProPublica for example could code
this add on that we used to collect those Facebook ads we used a Facebook add on. Yeah. No
it was Firefox add on to collect the Facebook ads but I think we could not have done this
internally. We don't have the people here. So yeah they're different different skills but also
different position of of those external collaboration partners that can really help.
Right. Right. So now that you've worked through several of these projects I mean is there
anything that you've noticed is particularly difficult or challenging and kind of pulling together
these investigations.
I think one one challenging aspect is the project management because you need project
management to skills at least to to really foster these investigations with many partners and with
many partners in house and externally. So so this is something that is not widespread in
journalistic organizations right now. So this is really important. And in Germany the most
challenging aspect besides that is that so many of the algorithms that private actors on the
stage is working with are not transparent right now so we have to set up experiments that can
reveal at least some discriminating factors or effects based on certain sets of outcomes but not
the algorithms themselves. So we would never be able to get a holistic picture of what they do.
If we can investigate the entire system so this is not that not that great about Germany right now
and in most cases we don't even know of algorithms that are used or not used for example in
predictive policing. We know that some units are using them, some are not using them and
there is no information available at all. So it is a serious use problem if you do those projects in
Germany right now.
Wow. Seems like a really really challenging beat to work on but maybe also that that challenge
can can motivate some more people to get interested in pursuing these things. On that note I
mean what kind of advice would you offer to other journalists or other news organizations that
are thinking about getting into the algorithms beat so to say. Yeah. What would be your advice
to them?
I think the most important thing is to do it anyway. Just um. I mean this is such an important
topic and we have to investigate on that. We have to look at algorithms and in our case I mean
we we are not that strong as a data team. And are these algorithms are not that transparent. But
at least we could do something. So any, every bit of transparency is really meaningful now or
useful. So I would first say you should do it. And besides that yeah collaboration can be
extremely helpful as we discussed with other teams with scientists, actors from different
systems who can approach algorithms in different ways. And it's also internally and newsrooms
for example some of those collaborations might not be that yet established in the past but it was
really really easy to to tell everyone why we do it this way and why we have to do it this way.
Then I think you should really take some time to set up a meaningful research design in the
beginning and also it would be use useful to speak with computer scientists or social and
cultural researchers about this topic because in the end the reliability of your results really is
based on this research design.
So it's the scientific process in the beginning and I think the most important thing in the end is to
to define your goals in a sound and comprehensive way. Because I mean first strong goal might
also be to raise awareness because many many people don't know about algorithms that are
working in certain fields of society so this is a goal in itself. It's really important.
And don't try to deconstruct the algorithm or to investigate every discriminatory effect it might
have because I think you wouldn't really need extensive datasets to do it in most cases they are
not available. And from the reader's perspective, I would say that the algorithm itself is not the
most interesting thing anyway. So they are really much more interested interested in the results
and what their personal impact might be that they can feel in their everyday lives. These small
bits might be also really important for the readers. So the reader's perspective is really
important. I think.
So something is better than nothing I guess. And just dive in. I think that's I think that's. I like that
approach.
Well so another topic of the MOOC this week is sort of more about transparency and how
journalists themselves can be more transparent in terms of the data and the algorithms that they
might be using in their own work.
I wonder if you could maybe tell us a little bit about how how you and how Der Spiegel sort of
approaches issues like transparency for big data journalism or big computational journalism
projects.
I think also it's a concerning this topic. You would need to distinguish distinguish between
different audiences here because when we think of our readers I think they really need
explanatory article about articles about our workflows and that I really see that we are really
transparent about methodology methodological problems and gaps in our datasets for example.
We of course link to our primary sources whenever this is possible. If it's not a link we can do
this of course and also publish raw data sets as a signal to them that we of course are willing to
to also share our sources.
But in my view it's it's really crucial not only to make everything accessible but also to explain
the limitations and implications. Oh sorry for the sounds. And in another way. So I think besides
that you could also think of maps or tables like just to it's to to make more raw data points
accessible that are interesting for reader groups but I don't think that the yeah that our code for
example is useful in this respect.
So on the other hand side when when we don't think about readers only but also about our
colleagues from different data from other data journalism teams or scientific researchers. We of
course share much more. We we share our methodology and of course explain our workflows.
We give them insights to our work for example be it on conferences or indirect prisoner
exchange. And there are also some students that work with our datasets.
So we do this but not publish everything on the Web site because this was would be really really
hard to do given that the team is quite small and we would have to to really clean up everything
afterwards in a much more extensive way than we do it either way. So yeah but.
So it creates additional work basically having to clean up and make sure it's publicly
publishable.
Yeah of course. Yeah. And we don't think that it's really some some some kind of signal that that
our readers really need. I think for them we should really be more explicit in explaining our
methodology and being transparent about those gaps and those problems that we have.
And what you can you can understand and what would be a misunderstanding like those
examples for example. Yeah but that. Yeah. When it comes to other colleagues or researchers
for example we we and the direct context you can also of course talk about those those
problems that that are occurring in every code snippet for example that you do.
This is really really helpful Christina. Any other parting words of words of wisdom from leading
these teams and sort of either investigating algorithms or trying to be transparent with
algorithms.
I think when it comes to algorithms and their role in society for example it's really really
important to have a diverse team. Oue team could be more diverse because you really have to
see those effects and those topics and it's so much easier if if if there are people on the team
that are really bringing this in from their personal view and from their reality in life. So yeah it
would be really really helpful to have a different, different fields in society or different regions or
different age groups in your team.
Of course a woman. And this is this is really really important because this is where the really
good questions come from from your everyday life. Also as a data journalist. Of course you
should also listen to your readers and should really ask them what what they want to know or
what they experience in their everyday life.
This was also quite helpful for these projects but to get in many different perspectives I think is a
crucial point and because this really gives your feelings for what an algorithm does and how it
discriminates maybe in certain groups in society.
I think that's I think that's perfect perfect advice and in a perfect way to close the interview. So
thank you again for spending some time with me and with the MOOC today. It was really great
to have you here. Thanks.
Thank you. You're welcome. Thanks.
